require(cluster)
require(neuralnet)
library(rpart)
library(mvtnorm)


#Number of times random data is generated and clustered for each number of countries
#short simulation
numSimulations=10
#full simulation
#numSimulations=100

#Different numbers of countries (instances) to simulate; 
#for each of number in this list there will be carried out numSimulations
#short simulation
listWithNumCountries=c(100,200,500,1000)
#full simulation
#listWithNumCountries=c(100,200,500,1000,2000, 5000, 10000)

countriesListLengt = length(listWithNumCountries)

#if FALSE, random uniform data is generated (there are no clusters in the data)
#if TRUE, data is generated using  multidimensional Gaussians (there are clusters in the data)
generateDataWithClusters = TRUE

#print each individual simulation
verbose = TRUE

#' Creates a dataset with numCountries instances with a random number of 
#' dimensions between 5 and 15. The values of each dimension are random  
#' uniformly distributed in the interval [0,1].
#' Therefore, there is no real cluster in the data returned by this function.
#' @param numCountries number of instances (rows) to generate
#' @return a dataframe with the random uniformly distributed data
createRandomUniformData <- function(numCountries) {
  numDim = sample(5:15, 1) 
  df = data.frame(matrix(NA, nrow =  numCountries, ncol = numDim))
  i=1
  while(i <= numDim) {
    colName=paste("X",i,sep = "")
    df[colName]=runif(numCountries,0,1)
    i=i+1
  }
  return(df)
}

#' Creates a dataset with numCountries instances with a random number of 
#' dimensions between 5 and 15. The instances are generated by a random number 
#' of multidimensional Gaussians (between 3 and 6 Gaussians) whose mean vector 
#' is made up by random numbers in the interval [-1, 1] and its covariance 
#' matrix is a diagonal matrix with a relatively small constant variance.
#' Therefore, the data returned by this function is organized in clusters.
#' @param numCountries number of instances (rows) to generate
#' @return a dataframe with the random gaussian data
numGausians=0
createRandomGaussianData <- function(numCountries) {
  numGausians <<- sample(4:6, 1)
  numDim = sample(5:15, 1)
  df=data.frame(matrix(NA, nrow =  numCountries, ncol = numDim))
  rowsPerGaussian=ceiling(numCountries/numGausians)
  i= 0
  while(i<numGausians){
    meanVector =  runif(numDim,min=-1,max=1) 
    dataPoint = rmvnorm(rowsPerGaussian, mean = meanVector, sigma = diag(numDim)/5)
    df[(i*rowsPerGaussian+1):((i+1)*rowsPerGaussian),] = dataPoint
    i= i+1
  }
  return(head(df,numCountries))
}

#Stores the results of accuracy of the decision tree for each simulation of each number of countries
accuracyTreeDef=matrix(nrow = numSimulations, ncol = countriesListLengt)
#Stores the accuracy of the optimized decision tree for each simulation of each number of countries
accuracyTree=matrix(nrow = numSimulations, ncol = countriesListLengt)
#Stores the results of accuracy of the neural network for each simulation of each number of countries
accuracyNNDef=matrix( nrow = numSimulations, ncol = countriesListLengt)
#Stores the results of accuracy of the optimized neural network for each simulation of each number of countries
accuracyNN=matrix( nrow = numSimulations, ncol = countriesListLengt)


#We start the simulations
contriesCount=0
#for each number of instances
for (numCountries in listWithNumCountries) {
  contriesCount=contriesCount+1
  simCount=1
  #for each number of simulations
  while(simCount<=numSimulations) {
    if(generateDataWithClusters){ 
      data = createRandomGaussianData(numCountries)
    } else { 
      data = createRandomUniformData(numCountries)
    }
    
    func=paste(names(data), collapse='+')
   
    k = sample(3:6, 1) #generate a random number of clusters between 3 and 6
    if(generateDataWithClusters==TRUE ){
      while(k==numGausians){
        k = sample(3:6, 1)
      }
    }
    print(paste("k:",k,"g",numGausians))
    cl = kmeans (data,centers=k) #cluster the data
    classTree = as.character(cl$cluster) #the decision tree requires a nominal class for prediction
    dfTree = data.frame(data,classTree) #data for training the tree with the nominal class
    classNN = cl$cluster #the neural network can use a metric value as a class
    dfNN = data.frame(data,classNN) #data to train the neural network with the metric class
    
    startTime <- Sys.time() #for log purposes
    
    #tree training with default parameters of the rpart function
    tree.trainedDef = rpart(as.formula(paste("classTree","~",func)), data=dfTree)
    #tree accuracy is calculated
    tree.predDef = predict(tree.trainedDef, data, type="class")
    accuracyTreeDef[simCount,contriesCount] = (sum(tree.predDef == classTree )/numCountries)
    
    #tree training with optimized parameters 
    tree.trained = rpart(as.formula(paste("classTree","~",func)), data=dfTree, minsplit=5, cp=0.001)
    #optimized tree accuracy is calculated
    tree.pred = predict(tree.trained, data, type="class")
    accuracyTree[simCount,contriesCount] = (sum(tree.pred == classTree )/numCountries)

    #training of a simple neural network with no hidden layers
    neuralNetDef <- tryCatch( 
      {setTimeLimit(120) #if training does not converge within two minutes we halt it
        neuralnet(as.formula(paste("classNN","~",func)),data=dfNN,
                  stepmax=1e+08,act.fct = "logistic",linear.output = TRUE)
      }, 
      #An error may occur if the default error is not reached in the maximum number of iterations (1e+08),
      #or if training takes more than 60 seconds
      error=function(e) e
    ) 
    if(inherits(neuralNetDef, "error")){ 
      next
    }
    
    #simple neural network accuracy is calculated
    PredictDef=compute(neuralNetDef,data)
    accuracyNNDef[simCount,contriesCount] = (sum((PredictDef$net.result- cl$cluster)<0.5)/numCountries)
    
    #For larger data sets we are more permissive with the threshold for the partial derivatives of
    #the error of the neural net with two hidden layers. This will yield a more reasonable  
    #execution time of the training algorithm, at the cost of slightly lowering the final accuracy
    if(numCountries >= 10000){ 
      th = 1
    } else if (numCountries >= 2000){ #
      th = 0.25
    } else{ 
      th = 0.1
    }
    
    #training of a neural network with two hidden layers
    neuralNet <- tryCatch( 
      {setTimeLimit(1200) #if training does not converge within 20 minutes we halt it
        neuralnet(as.formula(paste("classNN","~",func)),data=dfNN, hidden=c(8,4), threshold = th, 
                   stepmax=1e+08, act.fct = "logistic",linear.output = TRUE)
        },
      error=function(e) e 
    )
    
    if(inherits(neuralNet, "error")){ 
      print("mal")#*b
      next
    }
    #the accuracy of the neural network with two hidden layers is calculated
    Predict=compute(neuralNet,data)
    accuracyNN[simCount,contriesCount] = (sum((Predict$net.result- cl$cluster)<0.5)/numCountries)

    #log results of this simulation
    if(verbose){
      print(paste( "ContriesCount:", contriesCount, "SimCount:", simCount , "NumCountries:", numCountries,
                "TreeDef: ", signif(accuracyTreeDef[simCount,contriesCount],3),"Tree: ", signif(accuracyTree[simCount,contriesCount],3),
                "NNDef", signif(accuracyNNDef[simCount,contriesCount],3),"NN ", signif(accuracyNN[simCount,contriesCount],3)))
   
      print(Sys.time() - startTime) #*
    }
    simCount=simCount+1
  }
}


apply(accuracyTreeDef,2, mean )
apply(accuracyTreeDef,2, sd )
apply(accuracyTree,2, mean )
apply(accuracyNNDef,2, mean )
apply(accuracyNNDef,2, sd )
apply(accuracyNN,2, mean )
apply(accuracyNN,2, sd )

par(mfcol = c(2, 2))
boxplot(accuracyTreeDef, names = listWithNumCountries, xlab = "Number of countries", ylim = c(0.5, 1),
        varwidth = TRUE, ylab = "Accuracy", main = "Decision tree with default parameters")

boxplot(accuracyTree, names = listWithNumCountries, xlab = "Number of countries", ylim = c(0.5, 1),
        varwidth = TRUE, ylab = "Accuracy", main = "Decision tree with optimized parameters")

boxplot(accuracyNNDef, names = listWithNumCountries, xlab = "Number of countries", ylim = c(0.5, 1),
        varwidth = TRUE, ylab = "Accuracy", main = "Simple neural network")

boxplot(accuracyNN, names = listWithNumCountries, xlab = "Number of countries", ylim = c(0.5, 1),
        varwidth = TRUE, ylab = "Accuracy", main = "Neural network with two hidden layers")
